{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9IZdANZrR0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#tf.random.set_seed(42)\n",
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6MRlgf0sMz7",
        "colab_type": "code",
        "outputId": "c1ec711b-df39-418d-aa03-1fcea1a7e236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "irisData = load_iris()\n",
        "\n",
        "\n",
        "X = irisData.data\n",
        "y = irisData.target\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y, random_state=42)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCHufLP4s6wR",
        "colab_type": "code",
        "outputId": "c025209b-c8dd-4058-bbd5-3f735f4cd684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)\n",
        "\n",
        "model_DNN = keras.models.Sequential()\n",
        "\n",
        "model_DNN.add(keras.layers.Dense(units=12, activation='relu', input_shape=X_train.shape[1:]))\n",
        "model_DNN.add(keras.layers.Dense(units=10, activation='relu'))\n",
        "model_DNN.add(keras.layers.Dense(units= 8, activation='relu'))\n",
        "model_DNN.add(keras.layers.Dense(units=6, activation='relu'))\n",
        "model_DNN.add(keras.layers.Dense(units=3, activation='sigmoid'))\n",
        "model_DNN.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                60        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                130       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 88        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 54        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 21        \n",
            "=================================================================\n",
            "Total params: 353\n",
            "Trainable params: 353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7MY6IgLtWlz",
        "colab_type": "code",
        "outputId": "7a09988e-9830-4b06-db36-aaed837b4d91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_DNN.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "model_DNN.fit(x=X_train_std, y=y_train, validation_split=0.1, epochs=50,batch_size=16)\n",
        "test_loss, test_accuracy = model_DNN.evaluate(x=X_test_std, y=y_test)\n",
        "print(test_loss,test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 108 samples, validate on 12 samples\n",
            "Epoch 1/50\n",
            "108/108 [==============================] - 0s 3ms/sample - loss: 1.0992 - acc: 0.2685 - val_loss: 1.1205 - val_acc: 0.0833\n",
            "Epoch 2/50\n",
            "108/108 [==============================] - 0s 172us/sample - loss: 1.0868 - acc: 0.3519 - val_loss: 1.1149 - val_acc: 0.0833\n",
            "Epoch 3/50\n",
            "108/108 [==============================] - 0s 127us/sample - loss: 1.0749 - acc: 0.3889 - val_loss: 1.1123 - val_acc: 0.1667\n",
            "Epoch 4/50\n",
            "108/108 [==============================] - 0s 122us/sample - loss: 1.0621 - acc: 0.4352 - val_loss: 1.1104 - val_acc: 0.2500\n",
            "Epoch 5/50\n",
            "108/108 [==============================] - 0s 128us/sample - loss: 1.0485 - acc: 0.4907 - val_loss: 1.1085 - val_acc: 0.1667\n",
            "Epoch 6/50\n",
            "108/108 [==============================] - 0s 127us/sample - loss: 1.0344 - acc: 0.5000 - val_loss: 1.1068 - val_acc: 0.1667\n",
            "Epoch 7/50\n",
            "108/108 [==============================] - 0s 140us/sample - loss: 1.0181 - acc: 0.4444 - val_loss: 1.1061 - val_acc: 0.1667\n",
            "Epoch 8/50\n",
            "108/108 [==============================] - 0s 121us/sample - loss: 0.9968 - acc: 0.3611 - val_loss: 1.1049 - val_acc: 0.0833\n",
            "Epoch 9/50\n",
            "108/108 [==============================] - 0s 140us/sample - loss: 0.9697 - acc: 0.3796 - val_loss: 1.1000 - val_acc: 0.0833\n",
            "Epoch 10/50\n",
            "108/108 [==============================] - 0s 151us/sample - loss: 0.9414 - acc: 0.3889 - val_loss: 1.0952 - val_acc: 0.0833\n",
            "Epoch 11/50\n",
            "108/108 [==============================] - 0s 137us/sample - loss: 0.9112 - acc: 0.3889 - val_loss: 1.0926 - val_acc: 0.0833\n",
            "Epoch 12/50\n",
            "108/108 [==============================] - 0s 130us/sample - loss: 0.8783 - acc: 0.3981 - val_loss: 1.0907 - val_acc: 0.0833\n",
            "Epoch 13/50\n",
            "108/108 [==============================] - 0s 137us/sample - loss: 0.8526 - acc: 0.3981 - val_loss: 1.0909 - val_acc: 0.0833\n",
            "Epoch 14/50\n",
            "108/108 [==============================] - 0s 124us/sample - loss: 0.8279 - acc: 0.4074 - val_loss: 1.0909 - val_acc: 0.0833\n",
            "Epoch 15/50\n",
            "108/108 [==============================] - 0s 140us/sample - loss: 0.8101 - acc: 0.4074 - val_loss: 1.0880 - val_acc: 0.0833\n",
            "Epoch 16/50\n",
            "108/108 [==============================] - 0s 124us/sample - loss: 0.7966 - acc: 0.4352 - val_loss: 1.0856 - val_acc: 0.1667\n",
            "Epoch 17/50\n",
            "108/108 [==============================] - 0s 131us/sample - loss: 0.7856 - acc: 0.4444 - val_loss: 1.0815 - val_acc: 0.1667\n",
            "Epoch 18/50\n",
            "108/108 [==============================] - 0s 138us/sample - loss: 0.7754 - acc: 0.4537 - val_loss: 1.0721 - val_acc: 0.2500\n",
            "Epoch 19/50\n",
            "108/108 [==============================] - 0s 130us/sample - loss: 0.7664 - acc: 0.4722 - val_loss: 1.0603 - val_acc: 0.2500\n",
            "Epoch 20/50\n",
            "108/108 [==============================] - 0s 128us/sample - loss: 0.7569 - acc: 0.5093 - val_loss: 1.0479 - val_acc: 0.2500\n",
            "Epoch 21/50\n",
            "108/108 [==============================] - 0s 140us/sample - loss: 0.7466 - acc: 0.5370 - val_loss: 1.0360 - val_acc: 0.2500\n",
            "Epoch 22/50\n",
            "108/108 [==============================] - 0s 154us/sample - loss: 0.7362 - acc: 0.5370 - val_loss: 1.0204 - val_acc: 0.2500\n",
            "Epoch 23/50\n",
            "108/108 [==============================] - 0s 133us/sample - loss: 0.7232 - acc: 0.5463 - val_loss: 1.0033 - val_acc: 0.2500\n",
            "Epoch 24/50\n",
            "108/108 [==============================] - 0s 123us/sample - loss: 0.7110 - acc: 0.5556 - val_loss: 0.9862 - val_acc: 0.2500\n",
            "Epoch 25/50\n",
            "108/108 [==============================] - 0s 182us/sample - loss: 0.6944 - acc: 0.5648 - val_loss: 0.9700 - val_acc: 0.2500\n",
            "Epoch 26/50\n",
            "108/108 [==============================] - 0s 122us/sample - loss: 0.6774 - acc: 0.5741 - val_loss: 0.9419 - val_acc: 0.2500\n",
            "Epoch 27/50\n",
            "108/108 [==============================] - 0s 126us/sample - loss: 0.6622 - acc: 0.5833 - val_loss: 0.9148 - val_acc: 0.2500\n",
            "Epoch 28/50\n",
            "108/108 [==============================] - 0s 124us/sample - loss: 0.6462 - acc: 0.5741 - val_loss: 0.8977 - val_acc: 0.2500\n",
            "Epoch 29/50\n",
            "108/108 [==============================] - 0s 129us/sample - loss: 0.6313 - acc: 0.5741 - val_loss: 0.8779 - val_acc: 0.2500\n",
            "Epoch 30/50\n",
            "108/108 [==============================] - 0s 170us/sample - loss: 0.6154 - acc: 0.5833 - val_loss: 0.8556 - val_acc: 0.2500\n",
            "Epoch 31/50\n",
            "108/108 [==============================] - 0s 126us/sample - loss: 0.6009 - acc: 0.6111 - val_loss: 0.8320 - val_acc: 0.2500\n",
            "Epoch 32/50\n",
            "108/108 [==============================] - 0s 150us/sample - loss: 0.5851 - acc: 0.6111 - val_loss: 0.8173 - val_acc: 0.2500\n",
            "Epoch 33/50\n",
            "108/108 [==============================] - 0s 140us/sample - loss: 0.5712 - acc: 0.6111 - val_loss: 0.8079 - val_acc: 0.2500\n",
            "Epoch 34/50\n",
            "108/108 [==============================] - 0s 159us/sample - loss: 0.5571 - acc: 0.6111 - val_loss: 0.7979 - val_acc: 0.2500\n",
            "Epoch 35/50\n",
            "108/108 [==============================] - 0s 160us/sample - loss: 0.5444 - acc: 0.6111 - val_loss: 0.7705 - val_acc: 0.4167\n",
            "Epoch 36/50\n",
            "108/108 [==============================] - 0s 164us/sample - loss: 0.5315 - acc: 0.6296 - val_loss: 0.7481 - val_acc: 0.4167\n",
            "Epoch 37/50\n",
            "108/108 [==============================] - 0s 136us/sample - loss: 0.5227 - acc: 0.6296 - val_loss: 0.7336 - val_acc: 0.4167\n",
            "Epoch 38/50\n",
            "108/108 [==============================] - 0s 129us/sample - loss: 0.5102 - acc: 0.6204 - val_loss: 0.7297 - val_acc: 0.4167\n",
            "Epoch 39/50\n",
            "108/108 [==============================] - 0s 137us/sample - loss: 0.4997 - acc: 0.6204 - val_loss: 0.7177 - val_acc: 0.4167\n",
            "Epoch 40/50\n",
            "108/108 [==============================] - 0s 128us/sample - loss: 0.4912 - acc: 0.6296 - val_loss: 0.7059 - val_acc: 0.4167\n",
            "Epoch 41/50\n",
            "108/108 [==============================] - 0s 182us/sample - loss: 0.4833 - acc: 0.6296 - val_loss: 0.6810 - val_acc: 0.4167\n",
            "Epoch 42/50\n",
            "108/108 [==============================] - 0s 139us/sample - loss: 0.4745 - acc: 0.6389 - val_loss: 0.6787 - val_acc: 0.4167\n",
            "Epoch 43/50\n",
            "108/108 [==============================] - 0s 154us/sample - loss: 0.4650 - acc: 0.6481 - val_loss: 0.6665 - val_acc: 0.4167\n",
            "Epoch 44/50\n",
            "108/108 [==============================] - 0s 180us/sample - loss: 0.4583 - acc: 0.6481 - val_loss: 0.6524 - val_acc: 0.5833\n",
            "Epoch 45/50\n",
            "108/108 [==============================] - 0s 138us/sample - loss: 0.4500 - acc: 0.7037 - val_loss: 0.6430 - val_acc: 1.0000\n",
            "Epoch 46/50\n",
            "108/108 [==============================] - 0s 135us/sample - loss: 0.4424 - acc: 0.9167 - val_loss: 0.6281 - val_acc: 1.0000\n",
            "Epoch 47/50\n",
            "108/108 [==============================] - 0s 135us/sample - loss: 0.4367 - acc: 0.9444 - val_loss: 0.6142 - val_acc: 1.0000\n",
            "Epoch 48/50\n",
            "108/108 [==============================] - 0s 138us/sample - loss: 0.4303 - acc: 0.9444 - val_loss: 0.6047 - val_acc: 1.0000\n",
            "Epoch 49/50\n",
            "108/108 [==============================] - 0s 125us/sample - loss: 0.4223 - acc: 0.9352 - val_loss: 0.6075 - val_acc: 1.0000\n",
            "Epoch 50/50\n",
            "108/108 [==============================] - 0s 131us/sample - loss: 0.4176 - acc: 0.9352 - val_loss: 0.5983 - val_acc: 1.0000\n",
            "30/30 [==============================] - 0s 23us/sample - loss: 0.5120 - acc: 0.8667\n",
            "0.5120453238487244 0.8666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sthf40nquZhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}